{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "299fa778-709c-475a-b51b-69aa77790b89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d43b0ab6-7697-457a-a3f4-9b4be63dcc49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained('google/flan-t5-large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe3290e1-bba0-45c8-aa98-568b2cb83548",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('google/flan-t5-large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8819280c-fe7a-4181-92e8-03679e4e326b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "my_text = \"\"\"Summerize text:\n",
    "\n",
    "US lawmakers are working to secure the votes needed to pass a bipartisan deal that will temporarily suspend the nation's debt ceiling.\n",
    "\n",
    "Democrat and Republican leaders say they expect it will be approved, but some lawmakers have said they will vote against it.\n",
    "\n",
    "The package must pass in the narrowly-divided House of Representatives before it is voted on in the Senate.\n",
    "\n",
    "The US may default on its debt by 5 June without action being taken.\n",
    "\n",
    "President Joe Biden called the agreement a \"compromise\" after a deal was reached over the weekend, while Republican House Speaker Kevin McCarthy said it was \"worthy of the American people\".\n",
    "\n",
    "Negotiators have been working to sell the package on the Memorial Day federal holiday on Monday, according to US media, with both parties holding separate calls and meetings on the bill.\n",
    "\n",
    "The House and Senate are expected to return to the Capitol on Tuesday. A vote on the bill in the House of Representative is scheduled for Wednesday, lawmakers said.\n",
    "\n",
    "The proposed deal comes after long and bitter negotiations between Democrats and Republicans.\n",
    "\n",
    "It includes suspending the debt ceiling until the first quarter of 2025, rather than raising it by a specific amount, as well as a cap on non-defence spending until 2024.\n",
    "\n",
    "A text of the bill, titled the Fiscal Responsibility Act, was made public on Sunday.\n",
    "\n",
    "A simple guide to the US debt ceiling\n",
    "What's in the US debt ceiling deal?\n",
    "That same day, Mr Biden told reporters that he does not believe his party made too many concessions in the agreement.\n",
    "\n",
    "\"This is a deal that is good news,\" Mr Biden said. \"It takes the threat of catastrophic default off the table, protects our hard-earned and historic economic recovery.\"\n",
    "\n",
    "Hakeem Jeffries, the Democratic House minority leader, told CBS that he believes his party will support it.\n",
    "\n",
    "\"I do expect that there will be Democratic support once we have the ability to actually be fully briefed by the White House,\" Mr Jeffries said on Sunday. \"But I'm not going to predict what those numbers may ultimately look like.\"\n",
    "\n",
    "But Ro Khanna, a California Democrat and member of the House Progressive Caucus, told NBC News on Sunday night that a \"large majority\" of House Democrats are \"in flux\" on whether they would lend their support.\n",
    "\n",
    "Meanwhile, Mr McCarthy said on Sunday that he expects over 95% of House Republicans will support the bill.\n",
    "\n",
    "In an opinion piece published in the Wall Street Journal late on Sunday, Mr McCarthy hailed the agreement as a hard-fought win for Republicans.\n",
    "\n",
    "\"We are changing the direction in Washington through a responsible debt-limit increase that cuts spending, saves taxpayers money and restores economic growth,\" he wrote.\n",
    "\n",
    "During negotiations, Republicans had been seeking spending cuts in areas such as education and other social programmes in exchange for raising the $31.4tn (£25tn) debt limit.\n",
    "\n",
    "As the 99-page proposed agreement was made public, some of the most conservative Republicans voiced concerns that the deal does not cut future spending enough. Republican Chip Roy of Texas said on Twitter that he and some others were going to try to stop it passing.\n",
    "\n",
    "Some Democrats said they worried about changes in the agreement to the food stamps programme.\n",
    "\n",
    "Aside from addressing the debt ceiling limit, the bill also proposed raising the age from 50 to 54 for those who are required to work in order to receive food benefits.\n",
    "\n",
    "At the same time, it proposed eliminating work requirements for veterans and people who are homeless.\n",
    "\n",
    "Republicans control the House by 222 to 213, while Democrats control the Senate by 51 to 49.\n",
    "\n",
    "The Treasury had warned the US will run out of money if a deal is not passed.\n",
    "\n",
    "The US must borrow money to fund the government because it spends more than it raises in taxes.\n",
    "\n",
    "With the US dollar being the reserve currency of the world, a default would both upend the US economy and disrupt global markets.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "958b6147-5fc8-4fc2-a245-2d0a76093e96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inputs = tokenizer(my_text, return_tensors='pt')\n",
    "outputs = model.generate(**inputs,\n",
    "                        min_length=200,\n",
    "                        max_new_tokens=1000,\n",
    "                        num_beams=16,\n",
    "                        no_repeat_ngram_size=2,\n",
    "                        early_stopping=True)\n",
    "output_text_Flan_t5 = tokenizer.batch_decode(outputs,\n",
    "                                            skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24d369e9-e61b-43ec-ba9c-0523d82d68af",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Democratic House minority leader Hakeem Jeffries says he believes his party will support the bill. Republican House Speaker Kevin McCarthy hails the deal as a hard-fought win for Republicans. The US may default on its debt by 5 June without action being taken. Republicans had been seeking spending cuts in areas such as education and other social programmes in exchange for raising the $31.4tn debt limit. As the 99-page proposed agreement was made public on Sunday, some of the most conservative Republicans voiced concerns that it does not cut future spending enough. Some Democrats said they worried about changes in the agreement to the food stamps programme. A deal to temporarily suspend the nation's debt ceiling was reached over the weekend, with Democrats and Republicans holding separate calls and meetings on Monday. Negotiators have been working to sell the package on the Memorial Day federal holiday, according to US media. Democrat and Republican leaders say they expect it will be approved, but some lawmakers will vote against it.\"]\n"
     ]
    }
   ],
   "source": [
    "print(output_text_Flan_t5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b03d43e6-5b07-4cc3-8595-f6ba4e1b9596",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_id = \"samsum\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fde8273a-7d7a-4a56-a056-f0e500caaabe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\work\\python39\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Found cached dataset samsum (C:/Users/Cremator/.cache/huggingface/datasets/samsum/samsum/0.0.0/f1d7c6b7353e6de335d444e424dc002ef70d1277109031327bc9cc6af5d3d46e)\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 1000.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 14732\n",
      "Test dataset size: 819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load dataset from the hub\n",
    "dataset = load_dataset(dataset_id)\n",
    "\n",
    "print(f\"Train dataset size: {len(dataset['train'])}\")\n",
    "print(f\"Test dataset size: {len(dataset['test'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc342d07-1c11-4d88-bd45-35d659c1cc18",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dialogue: \n",
      "Camilla: I'm almost there\n",
      "Diana: I won't make it before 7, traffic is horrible today\n",
      "Elisabeth: Just don't race\n",
      "Diana: too late\n",
      "Elisabeth: what happened?\n",
      "Diana: we just had an accident\n",
      "Elisabeth: God, nothing serious I hope\n",
      "Camilla: Diana, are you there?\n",
      "Diana: sorry, no, a little crash but we're talking to this women that hit us\n",
      "Diana: a very unpleasant situation\n",
      "Camilla: is she insured \n",
      "Diana: she's not even sure\n",
      "Camilla: what a moron\n",
      "Diana: indeed\n",
      "Elisabeth: Diana, we will start without you then, join us when you manage to get out of it\n",
      "Diana: ok, sorry\n",
      "---------------\n",
      "summary: \n",
      "Diana had a car accident. Some woman hit them. She'll be late for her meeting with Camilla and Elisabeth. They'll start without her.\n",
      "---------------\n"
     ]
    }
   ],
   "source": [
    "from random import randrange\n",
    "\n",
    "\n",
    "sample = dataset['train'][randrange(len(dataset[\"train\"]))]\n",
    "print(f\"dialogue: \\n{sample['dialogue']}\\n---------------\")\n",
    "print(f\"summary: \\n{sample['summary']}\\n---------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "169f8bf1-0781-4006-884c-72ae0ea4b2c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "model_id=\"google/flan-t5-small\"\n",
    "\n",
    "# Load tokenizer of FLAN-t5-base\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1e3a8c1-229d-4c06-88b2-4a4b454f18ac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max source length: 512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max target length: 95\n"
     ]
    }
   ],
   "source": [
    "from datasets import concatenate_datasets\n",
    "\n",
    "# The maximum total input sequence length after tokenization.\n",
    "# Sequences longer than this will be truncated, sequences shorter will be padded.\n",
    "tokenized_inputs = concatenate_datasets([dataset[\"train\"], dataset[\"test\"]]).map(lambda x: tokenizer(x[\"dialogue\"], truncation=True), batched=True, remove_columns=[\"dialogue\", \"summary\"])\n",
    "max_source_length = max([len(x) for x in tokenized_inputs[\"input_ids\"]])\n",
    "print(f\"Max source length: {max_source_length}\")\n",
    "\n",
    "# The maximum total sequence length for target text after tokenization.\n",
    "# Sequences longer than this will be truncated, sequences shorter will be padded.\"\n",
    "tokenized_targets = concatenate_datasets([dataset[\"train\"], dataset[\"test\"]]).map(lambda x: tokenizer(x[\"summary\"], truncation=True), batched=True, remove_columns=[\"dialogue\", \"summary\"])\n",
    "max_target_length = max([len(x) for x in tokenized_targets[\"input_ids\"]])\n",
    "print(f\"Max target length: {max_target_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a997d4b5-1679-4fbb-92ab-4a4ce745442b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys of tokenized dataset: ['input_ids', 'attention_mask', 'labels']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "def preprocess_function(sample,padding=\"max_length\"):\n",
    "    # add prefix to the input for t5\n",
    "    inputs = [\"summarize: \" + item for item in sample[\"dialogue\"]]\n",
    "\n",
    "    # tokenize inputs\n",
    "    model_inputs = tokenizer(inputs, max_length=max_source_length, padding=padding, truncation=True)\n",
    "\n",
    "    # Tokenize targets with the `text_target` keyword argument\n",
    "    labels = tokenizer(text_target=sample[\"summary\"], max_length=max_target_length, padding=padding, truncation=True)\n",
    "\n",
    "    # If we are padding here, replace all tokenizer.pad_token_id in the labels by -100 when we want to ignore\n",
    "    # padding in the loss.\n",
    "    if padding == \"max_length\":\n",
    "        labels[\"input_ids\"] = [\n",
    "            [(l if l != tokenizer.pad_token_id else -100) for l in label] for label in labels[\"input_ids\"]\n",
    "        ]\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "tokenized_dataset = dataset.map(preprocess_function, batched=True, remove_columns=[\"dialogue\", \"summary\", \"id\"])\n",
    "print(f\"Keys of tokenized dataset: {list(tokenized_dataset['train'].features)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea91c98e-7391-4b09-8e27-efc1e6d33f86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM\n",
    "\n",
    "# huggingface hub model id\n",
    "model_id=\"google/flan-t5-small\"\n",
    "\n",
    "# load model from the hub\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3fc74b49-ef84-4c95-b783-215dbafc8c29",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Cremator\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "import nltk\n",
    "import numpy as np\n",
    "from nltk.tokenize import sent_tokenize\n",
    "nltk.download(\"punkt\")\n",
    "\n",
    "# Metric\n",
    "metric = evaluate.load(\"rouge\")\n",
    "\n",
    "# helper function to postprocess text\n",
    "def postprocess_text(preds, labels):\n",
    "    preds = [pred.strip() for pred in preds]\n",
    "    labels = [label.strip() for label in labels]\n",
    "\n",
    "    # rougeLSum expects newline after each sentence\n",
    "    preds = [\"\\n\".join(sent_tokenize(pred)) for pred in preds]\n",
    "    labels = [\"\\n\".join(sent_tokenize(label)) for label in labels]\n",
    "\n",
    "    return preds, labels\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "    if isinstance(preds, tuple):\n",
    "        preds = preds[0]\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "    # Replace -100 in the labels as we can't decode them.\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    # Some simple post-processing\n",
    "    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n",
    "\n",
    "    result = metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
    "    result = {k: round(v * 100, 4) for k, v in result.items()}\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea87668e-ae5c-4ba0-a071-efde26c632b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "# we want to ignore tokenizer pad token in the loss\n",
    "label_pad_token_id = -100\n",
    "# Data collator\n",
    "data_collator = DataCollatorForSeq2Seq(\n",
    "    tokenizer,\n",
    "    model=model,\n",
    "    label_pad_token_id=label_pad_token_id,\n",
    "    pad_to_multiple_of=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83bab386-5951-47aa-bfc3-801d5bedea53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import HfFolder\n",
    "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
    "\n",
    "# Hugging Face repository id\n",
    "repository_id = f\"{model_id.split('/')[1]}-{dataset_id}\"\n",
    "\n",
    "# Define training args\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    fp16=True,\n",
    "    output_dir=repository_id,\n",
    "    predict_with_generate=True,\n",
    "    learning_rate=5e-4,\n",
    "    num_train_epochs=5,\n",
    "    # logging & evaluation strategies\n",
    "    logging_dir=f\"{repository_id}/logs\",\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=500,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=2,\n",
    "    load_best_model_at_end=True,\n",
    "    # metric_for_best_model=\"overall_f1\",\n",
    "    # push to hub parameters\n",
    "    report_to=\"tensorboard\",\n",
    "    push_to_hub=False,\n",
    "    hub_strategy=\"every_save\",\n",
    "    hub_model_id=repository_id,\n",
    "    hub_token=HfFolder.get_token(),\n",
    "    gradient_accumulation_steps=2,\n",
    ")\n",
    "\n",
    "# Create Trainer instance\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ec2a8e4-a9fb-4bf3-b434-3e19e05af8aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Work\\Hillel_ML\\lesson_16\\transformers\\src\\transformers\\optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4605' max='4605' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4605/4605 41:54, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "      <th>Gen Len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>41.714400</td>\n",
       "      <td>17.710600</td>\n",
       "      <td>34.227100</td>\n",
       "      <td>38.091400</td>\n",
       "      <td>16.886447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>41.714400</td>\n",
       "      <td>17.710600</td>\n",
       "      <td>34.227100</td>\n",
       "      <td>38.091400</td>\n",
       "      <td>16.886447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>41.714400</td>\n",
       "      <td>17.710600</td>\n",
       "      <td>34.227100</td>\n",
       "      <td>38.091400</td>\n",
       "      <td>16.886447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>41.714400</td>\n",
       "      <td>17.710600</td>\n",
       "      <td>34.227100</td>\n",
       "      <td>38.091400</td>\n",
       "      <td>16.886447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>41.714400</td>\n",
       "      <td>17.710600</td>\n",
       "      <td>34.227100</td>\n",
       "      <td>38.091400</td>\n",
       "      <td>16.886447</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=4605, training_loss=0.0, metrics={'train_runtime': 2519.2074, 'train_samples_per_second': 29.239, 'train_steps_per_second': 1.828, 'total_flos': 1.369269457649664e+16, 'train_loss': 0.0, 'epoch': 5.0})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "287aa65a-b885-4623-aae4-87d92c4b0af5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='103' max='103' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [103/103 01:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': nan,\n",
       " 'eval_rouge1': 41.7144,\n",
       " 'eval_rouge2': 17.7106,\n",
       " 'eval_rougeL': 34.2271,\n",
       " 'eval_rougeLsum': 38.0914,\n",
       " 'eval_gen_len': 16.886446886446887,\n",
       " 'eval_runtime': 66.8035,\n",
       " 'eval_samples_per_second': 12.26,\n",
       " 'eval_steps_per_second': 1.542,\n",
       " 'epoch': 5.0}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3b046f30-5e0b-4a21-ac66-d371c8bcac5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer.save_pretrained(repository_id)\n",
    "trainer.create_model_card()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e1e20ec3-1d77-429f-8484-406c32d31b0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_path = repository_id\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "input_text = my_text[0:500]\n",
    "\n",
    "input_ids = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
    "\n",
    "output_ids = model.generate(input_ids)\n",
    "\n",
    "output_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "47d00178-5c96-4744-b87c-3e20be2ee174",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Senate bid to suspend the debt ceiling.\n"
     ]
    }
   ],
   "source": [
    "print(output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6255dc-f07e-425b-90db-147136333235",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
